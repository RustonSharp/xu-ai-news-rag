from tools import create_knowledge_base_tool, create_online_search_tool
from langchain_community.llms import Ollama
from langchain.agents import initialize_agent, AgentType
from langchain.agents import Tool

def create_assistant():
    """åˆ›å»ºä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œé›†æˆçŸ¥è¯†åº“å’Œåœ¨çº¿æœç´¢åŠŸèƒ½"""
    # ä½¿ç”¨æœ¬åœ°çš„Ollamaæ¨¡å‹
    model_name = "qwen2.5:3b"
    llm = Ollama(model=model_name, temperature=0)
    
    # åˆ›å»ºçŸ¥è¯†åº“å·¥å…·
    knowledge_base_tool = create_knowledge_base_tool()
    
    # åˆ›å»ºåœ¨çº¿æœç´¢å·¥å…·
    online_search_tool = create_online_search_tool()
    
    # å®šä¹‰å·¥å…·åˆ—è¡¨
    tools = [
        Tool(
            name="KnowledgeBase",
            func=lambda query: knowledge_base_tool.invoke({"action": "retrieve", "query": query, "k": 3, "rerank": True}),
            description="æœ¬åœ°æ–°é—»çŸ¥è¯†åº“å·¥å…·ï¼šåŒ…å«å®Œæ•´çš„æ–°é—»æ•°æ®ã€å†å²äº‹ä»¶ã€å®æ—¶ä¿¡æ¯ç­‰ã€‚è¿™æ˜¯ä¸»è¦çš„ä¿¡æ¯æ¥æºï¼Œåº”è¯¥ä¼˜å…ˆä½¿ç”¨ã€‚é€‚ç”¨äºæ‰€æœ‰ç±»å‹çš„æŸ¥è¯¢ï¼ŒåŒ…æ‹¬æœ€æ–°æ–°é—»ã€å†å²äº‹ä»¶ã€äººç‰©ä¿¡æ¯ç­‰ã€‚å¦‚æœè¿”å›çš„ç»“æœä¸é—®é¢˜ä¸ç›¸å…³ã€ä¸ºç©ºæˆ–åŒ…å«'Placeholder text'ï¼Œåˆ™å¿…é¡»ä½¿ç”¨OnlineSearchå·¥å…·ã€‚"
        ),
        Tool(
            name="OnlineSearch",
            func=online_search_tool.invoke,
            description="åœ¨çº¿æœç´¢å·¥å…·ï¼šå½“æœ¬åœ°çŸ¥è¯†åº“æ— æ³•æä¾›ç›¸å…³ä¿¡æ¯æ—¶å¿…é¡»ä½¿ç”¨æ­¤å·¥å…·ã€‚ä½¿ç”¨æ¡ä»¶ï¼š1)æœ¬åœ°çŸ¥è¯†åº“è¿”å›ç©ºç»“æœ 2)è¿”å›å†…å®¹ä¸é—®é¢˜ä¸ç›¸å…³ 3)è¿”å›å†…å®¹åŒ…å«'Placeholder text' 4)è¿”å›å†…å®¹æ— æ³•å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"
        )
    ]
    
    # è®¾ç½®agentå‚æ•°ï¼Œå¼ºè°ƒæœ¬åœ°çŸ¥è¯†åº“ä¼˜å…ˆç­–ç•¥
    agent_kwargs = {
        "system_message": """
        ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œä¸“é—¨ä¸ºæ–°é—»çŸ¥è¯†åº“ç³»ç»ŸæœåŠ¡ã€‚è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹æ­¥éª¤å·¥ä½œï¼š

        1. **é»˜è®¤ç­–ç•¥**ï¼šå§‹ç»ˆä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ–°é—»çŸ¥è¯†åº“å·¥å…·
           - æœ¬åœ°çŸ¥è¯†åº“åŒ…å«å®Œæ•´çš„æ–°é—»æ•°æ®ã€å†å²äº‹ä»¶ã€å®æ—¶ä¿¡æ¯ç­‰
           - å¯¹äºæ‰€æœ‰æŸ¥è¯¢ï¼Œé¦–å…ˆå°è¯•ä»æœ¬åœ°çŸ¥è¯†åº“è·å–ä¿¡æ¯

        2. **æœç´¢ç­–ç•¥**ï¼š
           - åˆ†æç”¨æˆ·é—®é¢˜ï¼Œæå–å…³é”®æœç´¢è¯
           - ä½¿ç”¨æå–çš„å…³é”®è¯æŸ¥è¯¢æœ¬åœ°çŸ¥è¯†åº“
           - å¦‚æœæœ¬åœ°çŸ¥è¯†åº“è¿”å›çš„ç»“æœä¸é—®é¢˜ä¸ç›¸å…³ã€ä¸ºç©ºæˆ–å†…å®¹ä¸º"Placeholder text"ï¼Œåˆ™å¿…é¡»ä½¿ç”¨åœ¨çº¿æœç´¢

        3. **å·¥å…·ä½¿ç”¨é¡ºåº**ï¼š
           - ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨KnowledgeBaseå·¥å…·æŸ¥è¯¢æœ¬åœ°çŸ¥è¯†åº“
           - ç¬¬äºŒæ­¥ï¼šè¯„ä¼°æœ¬åœ°çŸ¥è¯†åº“ç»“æœæ˜¯å¦ç›¸å…³å’Œæœ‰ç”¨
           - ç¬¬ä¸‰æ­¥ï¼šå¦‚æœæœ¬åœ°ç»“æœä¸ç›¸å…³æˆ–æ— ç”¨ï¼Œç«‹å³ä½¿ç”¨OnlineSearchå·¥å…·
           - ç¬¬å››æ­¥ï¼šåŸºäºæœç´¢ç»“æœæä¾›å‡†ç¡®ã€æœ‰ä¾æ®çš„å›ç­”

        4. **ç»“æœè¯„ä¼°æ ‡å‡†**ï¼š
           - å¦‚æœæœ¬åœ°çŸ¥è¯†åº“è¿”å›çš„å†…å®¹ä¸ç”¨æˆ·é—®é¢˜ä¸åŒ¹é…
           - å¦‚æœè¿”å›çš„å†…å®¹ä¸ºç©ºæˆ–åŒ…å«"Placeholder text"
           - å¦‚æœè¿”å›çš„å†…å®¹æ— æ³•å›ç­”ç”¨æˆ·çš„é—®é¢˜
           - æ»¡è¶³ä»¥ä¸Šä»»ä¸€æ¡ä»¶ï¼Œéƒ½å¿…é¡»ä½¿ç”¨åœ¨çº¿æœç´¢

        5. **å›ç­”è´¨é‡**ï¼š
           - ä¼˜å…ˆåŸºäºæœ¬åœ°çŸ¥è¯†åº“çš„ä¿¡æ¯å›ç­”é—®é¢˜
           - å¦‚æœæœ¬åœ°çŸ¥è¯†åº“ä¿¡æ¯ä¸è¶³ï¼Œå¿…é¡»ä½¿ç”¨åœ¨çº¿æœç´¢è¡¥å……
           - æ˜ç¡®æ ‡æ³¨ä¿¡æ¯æ¥æºï¼ˆæœ¬åœ°çŸ¥è¯†åº“ vs åœ¨çº¿æœç´¢ï¼‰
        """
    }
    
    # åˆå§‹åŒ–æ™ºèƒ½åŠ©æ‰‹ä»£ç†
    assistant = initialize_agent(
        tools=tools,
        llm=llm,
        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
        verbose=True,
        handle_parsing_errors=True,
        max_iterations=5,
        max_execution_time=180,  # 3åˆ†é’Ÿè¶…æ—¶
        agent_kwargs=agent_kwargs
    )
    
    return assistant

def query_with_sources(query):
    """æŸ¥è¯¢å¹¶åŸºäºæ£€ç´¢åˆ°çš„æ¥æºç”Ÿæˆæœ‰ä¾æ®çš„å›ç­”"""
    # ä½¿ç”¨LLMæå–å…³é”®è¯ï¼Œä¼˜åŒ–æœ¬åœ°çŸ¥è¯†åº“æœç´¢
    llm = Ollama(model="qwen2.5:3b", temperature=0)
    
    # æå–æœç´¢å…³é”®è¯
    keyword_prompt = f"""
    åˆ†æä»¥ä¸‹ç”¨æˆ·é—®é¢˜ï¼Œæå–æœ€é€‚åˆåœ¨æ–°é—»çŸ¥è¯†åº“ä¸­æœç´¢çš„å…³é”®è¯ï¼š
    
    ç”¨æˆ·é—®é¢˜ï¼š{query}
    
    è¯·æå–2-4ä¸ªå…³é”®è¯ï¼Œç”¨äºåœ¨æœ¬åœ°æ–°é—»çŸ¥è¯†åº“ä¸­æœç´¢ç›¸å…³ä¿¡æ¯ã€‚
    å…³é”®è¯åº”è¯¥ç®€æ´ã€å‡†ç¡®ï¼Œèƒ½å¤ŸåŒ¹é…æ–°é—»å†…å®¹ã€‚
    
    è¯·å›ç­”æ ¼å¼ï¼š
    æœç´¢å…³é”®è¯ï¼š[å…³é”®è¯1, å…³é”®è¯2, å…³é”®è¯3]
    """
    
    keyword_analysis = llm.invoke(keyword_prompt)
    print(f"å…³é”®è¯åˆ†æï¼š{keyword_analysis}")
    
    # åˆ›å»ºå·¥å…·
    knowledge_base_tool = create_knowledge_base_tool()
    online_search_tool = create_online_search_tool()
    
    raw_sources = []
    origin = "none"
    
    # ç¬¬ä¸€æ­¥ï¼šå§‹ç»ˆä¼˜å…ˆæŸ¥è¯¢æœ¬åœ°çŸ¥è¯†åº“
    print("æ­£åœ¨æŸ¥è¯¢æœ¬åœ°æ–°é—»çŸ¥è¯†åº“...")
    raw_sources = knowledge_base_tool.invoke({"action": "retrieve", "query": query, "k": 5, "rerank": True})
    origin = "knowledge_base"
    
    # æ£€æŸ¥çŸ¥è¯†åº“ç»“æœæ˜¯å¦æœ‰æ•ˆå’Œç›¸å…³
    def is_knowledge_base_result_invalid(sources, user_query):
        if not isinstance(sources, list) or len(sources) == 0:
            return True
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ç»“æœéƒ½æ˜¯å ä½ç¬¦æ–‡æœ¬
        all_placeholder = True
        for source in sources:
            content = str(source.get("content", "")).strip()
            if content and content != "Placeholder text":
                all_placeholder = False
                break
        
        if all_placeholder:
            return True
        
        # ä½¿ç”¨LLMåˆ¤æ–­ç»“æœæ˜¯å¦ä¸ç”¨æˆ·é—®é¢˜ç›¸å…³
        relevance_prompt = f"""
        åˆ¤æ–­ä»¥ä¸‹æœç´¢ç»“æœæ˜¯å¦ä¸ç”¨æˆ·é—®é¢˜ç›¸å…³ï¼š
        
        ç”¨æˆ·é—®é¢˜ï¼š{user_query}
        
        æœç´¢ç»“æœï¼š
        {str(sources[:2])}  # åªæ£€æŸ¥å‰2ä¸ªç»“æœ
        
        è¯·å›ç­”ï¼šç›¸å…³/ä¸ç›¸å…³
        åˆ¤æ–­æ ‡å‡†ï¼š
        1. å¦‚æœæœç´¢ç»“æœåŒ…å«ç”¨æˆ·é—®é¢˜ä¸­çš„å…³é”®è¯ï¼Œå›ç­”"ç›¸å…³"
        2. å¦‚æœæœç´¢ç»“æœä¸ç”¨æˆ·é—®é¢˜ä¸»é¢˜ç›¸å…³ï¼ˆå³ä½¿ä¸æ˜¯å®Œå…¨åŒ¹é…ï¼‰ï¼Œå›ç­”"ç›¸å…³"
        3. åªæœ‰å½“æœç´¢ç»“æœä¸ç”¨æˆ·é—®é¢˜å®Œå…¨æ— å…³æ—¶ï¼Œæ‰å›ç­”"ä¸ç›¸å…³"
        
        æ³¨æ„ï¼šå¯¹äºç®€å•çš„æŸ¥è¯¢ï¼ˆå¦‚"ç¾å›½"ã€"ä¸­å›½"ç­‰ï¼‰ï¼Œåªè¦æœç´¢ç»“æœæ¶‰åŠè¯¥å›½å®¶/åœ°åŒºï¼Œå°±åº”è¯¥å›ç­”"ç›¸å…³"
        """
        
        try:
            print(f"ğŸ” æ­£åœ¨åˆ¤æ–­æœç´¢ç»“æœç›¸å…³æ€§...")
            print(f"ğŸ“ ç”¨æˆ·é—®é¢˜: {user_query}")
            print(f"ğŸ“„ æœç´¢ç»“æœ: {sources[:2]}")
            relevance_check = llm.invoke(relevance_prompt)
            print(f"ğŸ¤– LLMç›¸å…³æ€§åˆ¤æ–­: {relevance_check}")
            if "ä¸ç›¸å…³" in relevance_check:
                print("âŒ LLMåˆ¤æ–­ç»“æœä¸ç›¸å…³ï¼Œå°†ä½¿ç”¨åœ¨çº¿æœç´¢")
                return True
            else:
                print("âœ… LLMåˆ¤æ–­ç»“æœç›¸å…³ï¼Œä½¿ç”¨æœ¬åœ°çŸ¥è¯†åº“ç»“æœ")
        except Exception as e:
            print(f"âš ï¸ LLMç›¸å…³æ€§åˆ¤æ–­å¤±è´¥: {str(e)}ï¼Œç»§ç»­ä½¿ç”¨åŸå§‹ç»“æœ")
            pass  # å¦‚æœåˆ¤æ–­å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨åŸå§‹ç»“æœ
        
        return False
    
    is_knowledge_base_empty = is_knowledge_base_result_invalid(raw_sources, query)
    
    # ç¬¬äºŒæ­¥ï¼šå¦‚æœæœ¬åœ°çŸ¥è¯†åº“æ²¡æœ‰æœ‰æ•ˆç»“æœï¼Œæ‰ä½¿ç”¨åœ¨çº¿æœç´¢
    if is_knowledge_base_empty:
        print("æœ¬åœ°çŸ¥è¯†åº“æ— ç›¸å…³æ•°æ®ï¼Œæ­£åœ¨ä½¿ç”¨åœ¨çº¿æœç´¢...")
        origin = "online_search"
        raw_sources = online_search_tool.invoke(query)
        if not isinstance(raw_sources, list):
            raw_sources = []
    else:
        print("æœ¬åœ°çŸ¥è¯†åº“æ‰¾åˆ°ç›¸å…³æ•°æ®ï¼Œä½¿ç”¨æœ¬åœ°ç»“æœ")

    # ç”¨æ£€ç´¢åˆ°çš„æ¥æºæ¥çº¦æŸç”Ÿæˆï¼Œé¿å…æ¨¡å‹è·‘é¢˜
    # ç®€å•ç›¸å…³æ€§è¿‡æ»¤ï¼šä»…ä¿ç•™æ ‡é¢˜/å†…å®¹åŒ…å«æŸ¥è¯¢å…³é”®è¯çš„æ¥æº
    def filter_relevant_sources(q, sources):
        try:
            q_terms = [t.strip().lower() for t in q.split() if t.strip()]
            if not q_terms:
                q_terms = [q.lower()]
        except Exception:
            q_terms = [str(q).lower()]
        filtered = []
        for s in sources or []:
            try:
                title = s.get("metadata", {}).get("title", "") if isinstance(s.get("metadata", {}), dict) else s.get("title", "")
                content = s.get("content", "")
                hay = (title or "") + "\n" + (content or "")
                hay_lower = hay.lower()
                if any(term and term in hay_lower for term in q_terms):
                    filtered.append(s)
            except Exception:
                continue
        return filtered

    relevant_sources = filter_relevant_sources(query, raw_sources)
    # è‹¥è¿‡æ»¤åä¸ºç©ºï¼Œåˆ™ä»ä½¿ç”¨åŸå§‹sourcesï¼Œä½†åœ¨æç¤ºä¸­è¦æ±‚å¿½ç•¥æ— å…³å†…å®¹
    sources_for_prompt = relevant_sources if len(relevant_sources) > 0 else (raw_sources if isinstance(raw_sources, list) else [])

    def format_sources(sources):
        lines = []
        for i, s in enumerate(sources[:3], 1):
            try:
                title = s.get("metadata", {}).get("title", "") if isinstance(s.get("metadata", {}), dict) else s.get("title", "")
                content = s.get("content", "")
                url = s.get("url", "")
                lines.append(f"[æ¥æº{i}] æ ‡é¢˜: {title}\nå†…å®¹: {content}\né“¾æ¥: {url}")
            except Exception:
                lines.append(str(s))
        return "\n\n".join(lines) if lines else "(æ— )"

    sources_block = format_sources(sources_for_prompt)

    # ç›´æ¥ä½¿ç”¨åŒä¸€æ¨¡å‹è¿›è¡Œæœ‰ä¾æ®çš„å›ç­”
    llm = Ollama(model="qwen2.5:3b", temperature=0)
    prompt = (
        "ä½ æ˜¯ä¸€åæ™ºèƒ½åŠ©æ‰‹ã€‚åªä¾æ®ç»™å®šçš„èµ„æ–™ä½œç­”ï¼Œä¸è¦ç¼–é€ ã€‚\n"
        "è‹¥èµ„æ–™ä¸­å­˜åœ¨ä¸é—®é¢˜æ— å…³çš„å†…å®¹ï¼Œè¯·å¿½ç•¥æ— å…³å†…å®¹ã€‚\n"
        "å¦‚æœè‡³å°‘æœ‰ä¸€æ¡ç›¸å…³èµ„æ–™ï¼Œè¯·ç»™å‡ºä¸é—®é¢˜ä¸»é¢˜æœ€ç›¸å…³çš„è¦ç‚¹æ€»ç»“ï¼›\n"
        "ä»…å½“å®Œå…¨æ²¡æœ‰ç›¸å…³èµ„æ–™æ—¶å›å¤ï¼šâ€˜æš‚æ— èµ„æ–™â€™ã€‚\n"
        "è¯·ç”¨ç®€æ´ä¸­æ–‡å›ç­”ã€‚\n\n"
        f"ç”¨æˆ·é—®é¢˜ï¼š{query}\n\n"
        f"èµ„æ–™å¦‚ä¸‹ï¼š\n{sources_block}\n\n"
        "åŸºäºä»¥ä¸Šèµ„æ–™ï¼Œç»™å‡ºç›´æ¥ç­”æ¡ˆï¼š"
    )
    final_answer = llm.invoke(prompt)

    return {
        "answer": final_answer,
        "raw_sources": raw_sources,
        "origin": origin
    }

if __name__ == "__main__":
    # åˆ›å»ºå¹¶æµ‹è¯•åŠ©æ‰‹
    assistant = create_assistant()
    
    # æµ‹è¯•æŸ¥è¯¢ - æ‰€æœ‰é—®é¢˜éƒ½åº”è¯¥ä¼˜å…ˆæŸ¥è¯¢æœ¬åœ°æ–°é—»çŸ¥è¯†åº“
    test_queries = [
        "å›½æ°‘å…šä¸»å¸­é€‰ä¸¾",  # åº”è¯¥èƒ½åœ¨æœ¬åœ°çŸ¥è¯†åº“æ‰¾åˆ°
        "æœ€è¿‘æœ‰ä»€ä¹ˆç¾å®³å—",  # æœ¬åœ°å¯èƒ½æ²¡æœ‰ï¼Œåº”è¯¥fallbackåˆ°åœ¨çº¿æœç´¢
        "ä»Šå¤©è‚¡å¸‚è¡Œæƒ…å¦‚ä½•",  # æœ¬åœ°å¯èƒ½æ²¡æœ‰ï¼Œåº”è¯¥fallbackåˆ°åœ¨çº¿æœç´¢
        "äººå·¥æ™ºèƒ½æœ€æ–°å‘å±•",  # æœ¬åœ°å¯èƒ½æ²¡æœ‰ï¼Œåº”è¯¥fallbackåˆ°åœ¨çº¿æœç´¢
    ]
    
    print("=== æ™ºèƒ½åŠ©æ‰‹æµ‹è¯• ===")
    for query in test_queries:
        print(f"\n{'='*50}")
        print(f"é—®é¢˜: {query}")
        print("-" * 50)
        try:
            result = assistant.invoke(query)
            print(f"å›ç­”: {result}")
        except Exception as e:
            print(f"æŸ¥è¯¢å‡ºé”™: {str(e)}")
    
    print(f"\n{'='*50}")
    print("=== å¸¦æ¥æºçš„æŸ¥è¯¢æµ‹è¯• ===")
    for query in test_queries[:2]:  # åªæµ‹è¯•å‰ä¸¤ä¸ªé—®é¢˜
        print(f"\n{'='*50}")
        print(f"é—®é¢˜: {query}")
        print("-" * 50)
        try:
            result = query_with_sources(query)
            print(f"å›ç­”: {result['answer']}")
            print(f"æ¥æº: {result['origin']}")
        except Exception as e:
            print(f"æŸ¥è¯¢å‡ºé”™: {str(e)}")